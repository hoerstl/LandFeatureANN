{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7770d26-ecc4-42b9-aef1-b6e2b4434acd",
   "metadata": {},
   "source": [
    "<h1>Land Feature CNN</h1>\n",
    "\n",
    "Code and network framework gathered from:\n",
    "https://www.tensorflow.org/tutorials/images/cnn\n",
    "\n",
    "Authors:\n",
    "- Thao Pham\n",
    "- Lawrence Hoerst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d98a4-52e2-4209-9bd6-58a856721948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf \n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "import pickle\n",
    "\n",
    "# list files in a directory\n",
    "import os\n",
    "\n",
    "# Maybe I can take out datasets\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9d279b0-9cdd-4d8b-b8dd-1dc74623bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_image_names(nameList):\n",
    "    \n",
    "    # We need to sort this list twice since one sort gives that, for example '59.png' < '6.png' when we want to see 6 first.\n",
    "    # Therefore, we need to sort first by numbering and then by length of the file to get the 1, 2, 3, 4, ... behavior we want to see\n",
    "    return sorted(sorted(nameList), key=lambda e: len(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86f2506f-0fba-44ce-ab09-88d2cc836bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_processing(images_path):\n",
    "    global colors_to_code\n",
    "    images_array = []\n",
    "\n",
    "    # Load images:\n",
    "    sorted_image_names = sort_image_names(os.listdir(images_path))\n",
    "    for train_image_name in sorted_image_names:\n",
    "\n",
    "        # concatenate directory paths with filenames or additional directories that is correct for the host operating system\n",
    "        images_join_path = os.path.join(images_path, train_image_name)\n",
    "\n",
    "        # open images:\n",
    "        train_image = Image.open(images_join_path)\n",
    "\n",
    "        # Resize images:\n",
    "        train_image = train_image.resize((200,200))\n",
    "        \n",
    "        # Convert images to numpy array:\n",
    "        # Each pixel will have three values corresponding to the RGB channels:\n",
    "        train_image_np = np.array(train_image)\n",
    "        train_codified_image = np.zeros((len(train_image_np), len(train_image_np[0]), 1))\n",
    "        for i in range(len(train_image_np)):\n",
    "            for j in range(len(train_image_np[0])):\n",
    "                if tuple(train_image_np[i][j]) in colors_to_code:\n",
    "                    train_codified_image[i][j] = colors_to_code[tuple(train_image_np[i][j])]\n",
    "                else:\n",
    "                    train_codified_image[i][j] = colors_to_code['default']\n",
    "\n",
    "        # normalize the pixel values between 0 and 1:\n",
    "        # train_image_np = train_image_np / 255.0\n",
    "        images_array.append(train_codified_image)\n",
    "    \n",
    "    return np.array(images_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f28bee-41b6-4438-b8da-636f9188e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoWayDict(dict):\n",
    "    \"\"\"\n",
    "    Class and functionality taken from stack overflow:\n",
    "    https://stackoverflow.com/questions/1456373/two-way-reverse-map#:~:text=class%20TwoWayDict(,__len__(self)%20//%202\n",
    "    \"\"\"\n",
    "    def __setitem__(self, key, value):\n",
    "        # Remove any previous connections with these values\n",
    "        if key in self:\n",
    "            del self[key]\n",
    "        if value in self:\n",
    "            del self[value]\n",
    "        dict.__setitem__(self, key, value)\n",
    "        dict.__setitem__(self, value, key)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        dict.__delitem__(self, self[key])\n",
    "        dict.__delitem__(self, key)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of connections\"\"\"\n",
    "        return dict.__len__(self) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ba345-7669-48be-8ee8-347406a0f816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colored images converted successfully...\n",
      "Raw images converted successfully...\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      " 76644352/170498071 [============>.................] - ETA: 5s"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # CONVERTER\n",
    "    \n",
    "    global class_names, class_colors, class_codes, colors_to_code\n",
    "    # Class names to plot the images:\n",
    "    class_names = ['Water', 'Buildings', 'Roads', 'Foliage', 'Mineral deposits', 'Mountainous terrain', 'Rocky terrain', 'Sandy terrain', 'Plains', 'Snow', 'Grass']\n",
    "    class_colors = ['#0f5e9c', ('#f2f2f2', '#606060'), '#c4c4c4', '#3a5f0b', '#490e0e', '#5a7a4c', '#698287', '#f7ae64', '#c89e23', '#fffafa', '#7cfc00']\n",
    "    class_codes = {class_names[i]: i for i in range(len(class_names))}\n",
    "    \n",
    "    # hex_to_rgb\n",
    "    cvt = lambda hex: ImageColor.getcolor(hex, \"RGB\")\n",
    "    colors_to_code = {cvt('#0f5e9c'): 0,\n",
    "                      cvt('#f2f2f2'): 1, cvt('#606060'): 1,\n",
    "                      cvt('#c4c4c4'): 2,\n",
    "                      cvt('#3a5f0b'): 3,\n",
    "                      cvt('#490e0e'): 4,\n",
    "                      cvt('#5a7a4c'): 5,\n",
    "                      cvt('#698287'): 6,\n",
    "                      cvt('#f7ae64'): 7,\n",
    "                      cvt('#c89e23'): 8,\n",
    "                      cvt('#fffafa'): 9,\n",
    "                      cvt('#7cfc00'): 10,\n",
    "                      'default':      11}\n",
    "\n",
    "    colored_image_path = os.path.join(os.getcwd(), 'colored_images')\n",
    "    colored_image_array = images_processing(colored_image_path)\n",
    "\n",
    "    with open('training_outputs.pickle', 'wb') as training_file:\n",
    "        pickle.dump(colored_image_array, training_file)\n",
    "    print('Colored images converted successfully...')  \n",
    "    \n",
    "    colored_image_names = sort_image_names(os.listdir(colored_image_path))\n",
    "    raw_image_path = os.path.join(os.getcwd(), 'scaled')\n",
    "    colored_image_array = images_processing(raw_image_path)\n",
    "    \n",
    "    raw_image_array = []\n",
    "    for image_name in colored_image_names:  # for every colored image we loaded, load the raw image in the same order\n",
    "        img_path = os.path.join(raw_image_path, image_name)\n",
    "        train_image = Image.open(img_path)\n",
    "        train_image = train_image.resize((200,200))\n",
    "        train_image_np = np.array(train_image)\n",
    "        raw_image_array.append(train_image_np)\n",
    "        \n",
    "    with open('training_inputs.pickle', 'wb') as training_file:\n",
    "        pickle.dump(raw_image_array, training_file)\n",
    "    print('Raw images converted successfully...')\n",
    "\n",
    "    # NETWORK\n",
    "\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # unpickle our test data here\n",
    "    with open('training_inputs.pickle', 'rb') as inputsFile:\n",
    "        training_inputs = pickle.load(inputsFile)\n",
    "    with open('training_outputs.pickle', 'rb') as outputsFile:\n",
    "        training_outputs = pickle.load(outputsFile)\n",
    "        \n",
    "    # We need to decide on how many layers we want\n",
    "    # These parameters are not yet setup for our network\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(200, 200, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(200*200, activation='relu'))\n",
    "    model.add(layers.Dense(200*200))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(training_inputs, training_outputs, epochs=10)\n",
    "    \n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
